{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digit = load_digits()\n",
    "x = digit.data\n",
    "y = digit.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   7.,  15.,  13.,   1.,   0.,   0.,   0.,   8.,  13.,\n",
       "         6.,  15.,   4.,   0.,   0.,   0.,   2.,   1.,  13.,  13.,   0.,\n",
       "         0.,   0.,   0.,   0.,   2.,  15.,  11.,   1.,   0.,   0.,   0.,\n",
       "         0.,   0.,   1.,  12.,  12.,   1.,   0.,   0.,   0.,   0.,   0.,\n",
       "         1.,  10.,   8.,   0.,   0.,   0.,   8.,   4.,   5.,  14.,   9.,\n",
       "         0.,   0.,   0.,   7.,  13.,  13.,   9.,   0.,   0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f17b76e7438>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPcAAAD7CAYAAAC2TgIoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrUKsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f17b757a240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[1].reshape(8,8),cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size=0.25,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LogisticRegression()\n",
    "reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.444444444444443"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test,y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted\n",
       "0         1          1\n",
       "1         5          5\n",
       "2         0          0\n",
       "3         7          7\n",
       "4         1          1\n",
       "5         0          0\n",
       "6         6          6\n",
       "7         1          1\n",
       "8         5          5\n",
       "9         4          4\n",
       "10        9          9\n",
       "11        2          2\n",
       "12        7          7\n",
       "13        8          8\n",
       "14        4          4\n",
       "15        6          6\n",
       "16        9          9\n",
       "17        3          3\n",
       "18        7          7\n",
       "19        4          4\n",
       "20        7          7\n",
       "21        1          8\n",
       "22        8          8\n",
       "23        6          6\n",
       "24        0          0\n",
       "25        9          9\n",
       "26        6          6\n",
       "27        1          1\n",
       "28        3          3\n",
       "29        7          7\n",
       "..      ...        ...\n",
       "420       5          5\n",
       "421       4          4\n",
       "422       9          9\n",
       "423       0          0\n",
       "424       5          5\n",
       "425       9          9\n",
       "426       1          5\n",
       "427       4          4\n",
       "428       5          5\n",
       "429       0          0\n",
       "430       4          4\n",
       "431       3          3\n",
       "432       4          4\n",
       "433       2          2\n",
       "434       3          3\n",
       "435       9          9\n",
       "436       0          0\n",
       "437       8          8\n",
       "438       7          7\n",
       "439       8          8\n",
       "440       6          6\n",
       "441       9          9\n",
       "442       4          4\n",
       "443       5          5\n",
       "444       7          7\n",
       "445       8          8\n",
       "446       3          3\n",
       "447       7          7\n",
       "448       8          8\n",
       "449       3          3\n",
       "\n",
       "[450 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'actual':y_test,'predicted':pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Classification Metrics\n",
    "Classification problems are perhaps the most common type of machine learning problem and as such there are a myriad of metrics that can be used to evaluate predictions for these problems.\n",
    "In this section we will review how to use the following metrics:\n",
    "\n",
    "• Classification Accuracy.\n",
    "\n",
    "• Logarithmic Loss.\n",
    "\n",
    "• Confusion Matrix.\n",
    "\n",
    "• Classification Report.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.90555556,  0.95      ,  0.89444444,  0.91666667,  0.94444444,\n",
       "        0.97222222,  0.97777778,  0.95530726,  0.8603352 ,  0.93854749])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10,random_state = 7)\n",
    "\n",
    "results = model_selection.cross_val_score(reg,x,y,cv=kfold,scoring='accuracy')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93153010552451898"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.45780262, -0.14425175, -0.61747256, -0.27323632, -0.27567035,\n",
       "       -0.12823357, -0.11021432, -0.12333149, -0.62655102, -0.68631191])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(reg,x,y,cv=kfold,scoring='neg_log_loss')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.34430759138037381"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'https://sebastianraschka.com/images/faq/multiclass-metric/conf_mat.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51  0  0  0  2  0  0  0  0  0]\n",
      " [ 0 40  0  0  0  1  0  0  1  0]\n",
      " [ 0  1 39  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 49  0  0  0  0  3  0]\n",
      " [ 0  0  0  0 47  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 37  0  0  0  2]\n",
      " [ 0  0  0  0  0  0 43  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 47  0  1]\n",
      " [ 0  0  0  0  0  1  0  0 35  1]\n",
      " [ 0  0  0  0  0  1  0  0  1 46]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'https://www.safaribooksonline.com/library/view/python-data-analysis/9781785282287/graphics/B04223_10_02.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision is a measure that tells us what proportion of patients that we diagnosed as having cancer, actually had cancer\n",
    "\n",
    "- In our cancer example with 100 people, only 5 people have cancer. Let's say our model is very bad and predicts every case as Cancer. Since we are predicting everyone as having cancer, our denominator(True positives and False Positives) is 100 and the numerator, person having cancer and the model predicting his case as cancer is 5. So in this example, we can say that Precision of such model is 5%\n",
    "\n",
    "\n",
    "#### Recall is a measure that tells us what proportion of patients that actually had cancer was diagnosed by the algorithm as having cancer.\n",
    "\n",
    "\n",
    "- In our cancer example with 100 people, 5 people actually have cancer. Let's say that the model predicts every case as cancer. So our denominator(True positives and False Negatives) is 5 and the numerator, person having cancer and the model predicting his case as cancer is also 5(Since we predicted 5 cancer cases correctly). So in this example, we can say that the Recall of such model is 100%. And Precision of such a model(As we saw above) is 5%.\n",
    "\n",
    "\n",
    "\n",
    "It is clear that recall gives us information about a classifiers performance with respect to false negatives (how many did we miss), while precision gives us information about its performance with respect to false positives(how many did we caught).\n",
    "Precision is about being precise. So even if we managed to capture only one cancer case, and we captured it correctly, then we are 100% precise.\n",
    "Recall is not so much about capturing cases correctly but more about capturing all cases that have cancer with the answer as cancer. So if we simply always say every case as cancer, we have 100% recall.\n",
    "So basically if we want to focus more on minimising False Negatives, we would want our Recall to be as close to 100% as possible without precision being too bad and if we want to focus on minimizing False positives, then our focus should be to make Precision as close to 100% as possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        37\n",
      "          1       0.89      0.91      0.90        43\n",
      "          2       0.95      0.93      0.94        44\n",
      "          3       0.90      0.96      0.92        45\n",
      "          4       0.97      1.00      0.99        38\n",
      "          5       0.98      0.98      0.98        48\n",
      "          6       0.96      1.00      0.98        52\n",
      "          7       1.00      0.94      0.97        48\n",
      "          8       0.93      0.90      0.91        48\n",
      "          9       0.96      0.94      0.95        47\n",
      "\n",
      "avg / total       0.95      0.95      0.95       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73184699,  0.86942354,  0.81023661,  0.79423609,  0.82434177,\n",
       "        0.94343263,  0.92524112,  0.90725247,  0.60169024,  0.82555495])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(reg,x,y,cv=kfold,scoring='r2')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82332564041087808"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
